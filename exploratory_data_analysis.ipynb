{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf599b7-6ea7-4492-b25b-c858a5f4f825",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8e821f-8c22-41c3-a11a-1589ddef66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ae343f-ff25-431d-a853-da987c826153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/maziar/.cache/huggingface/datasets/json/default-44bd61d3faf6c7bb/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c2bd798f6f429992a658fe473cf53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files='alpaca-lora/alpaca_data_cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb61ef01-f0ff-4a75-8e29-9f936e3af3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction: Modify the sentence given by removing a word and output the modified sentence.\n",
      "input: The ship ventured into the dangerous storm.\n",
      "output: The ship ventured into the storm.\n"
     ]
    }
   ],
   "source": [
    "data_point = data[\"train\"].shuffle()[0]\n",
    "instruction = data_point['instruction']\n",
    "input = data_point['input']\n",
    "output = data_point['output']\n",
    "\n",
    "print(f'instruction: {instruction}')\n",
    "print(f'input: {input}')\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d239a48-e5eb-4aa5-8330-e965440ecdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('alpaca-lora/templates/alpaca.json') as fp:\n",
    "    template = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc11913-1f3e-47d4-aa16-bbb92e7a6d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Template used by Alpaca-LoRA.',\n",
       " 'prompt_input': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n',\n",
       " 'prompt_no_input': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n',\n",
       " 'response_split': '### Response:'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df58bbce-2a0c-493c-a185-405aaa06b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(template, instruction, input = None, label = None):\n",
    "    if input:\n",
    "        res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n",
    "    else:\n",
    "        res = template[\"prompt_no_input\"].format(instruction=instruction)\n",
    "    if label:\n",
    "        res = f\"{res}{label}\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2792c118-8d53-4699-9086-7518af4a881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Modify the sentence given by removing a word and output the modified sentence.\n",
      "\n",
      "### Input:\n",
      "The ship ventured into the dangerous storm.\n",
      "\n",
      "### Response:\n",
      "The ship ventured into the storm.\n"
     ]
    }
   ],
   "source": [
    "full_prompt = generate_prompt(template, instruction, input, output)\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ce70d-e196-4039-8cfd-a505bcea0fe0",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2a869b-0c64-457e-a109-60118395fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef076f98-b4cb-40a1-8d07-4b9353819705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained('LLaMA_HF/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39382c64-41a4-4dcb-a987-7638187ef58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = (0)\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e61d79-1a8b-4944-aed1-8aff90d6c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='LLaMA_HF/', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'pad_token': '<unk>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1ce983-0fce-42a5-b5f0-350bc2dd028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_len = 256\n",
    "tokenized_full_prompt = tokenizer(full_prompt, truncation=True, max_length=cutoff_len, padding=False, return_tensors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e8dbb2-9711-4aef-8583-ee8615c92f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2111, 1598, 278, 10541, 2183, 491, 11077, 263, 1734, 322, 1962, 278, 9120, 10541, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 18215, 14280, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 14280, 29889], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bcfd18b-be8e-44f4-997a-93ba81b06b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_eos_token = True\n",
    "if (tokenized_full_prompt[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "    and len(tokenized_full_prompt[\"input_ids\"]) < cutoff_len\n",
    "    and add_eos_token):\n",
    "    \n",
    "    tokenized_full_prompt[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "    tokenized_full_prompt[\"attention_mask\"].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa7ff8c-033a-4cc4-9ddf-f24d61e4619a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2111, 1598, 278, 10541, 2183, 491, 11077, 263, 1734, 322, 1962, 278, 9120, 10541, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 18215, 14280, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 14280, 29889, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1dd3b39-20b0-4c22-954d-2cac2d83f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_full_prompt[\"labels\"] = tokenized_full_prompt[\"input_ids\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74d844f-bddd-45f3-a83a-0bde2e9c89bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2111, 1598, 278, 10541, 2183, 491, 11077, 263, 1734, 322, 1962, 278, 9120, 10541, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 18215, 14280, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 14280, 29889, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2111, 1598, 278, 10541, 2183, 491, 11077, 263, 1734, 322, 1962, 278, 9120, 10541, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 18215, 14280, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 1576, 7751, 9712, 2955, 964, 278, 14280, 29889, 2]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c270601-08e1-4e3c-8ab8-721b731397da",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0066f0f4-172b-407a-b61e-e50a17cc9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f33d2e-df1a-4681-9e77-f1dfab16d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary /home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/maziar/miniconda3/envs/pytorch2 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/extras/CUPTI/lib64'), PosixPath('/usr/local/cuda-10.1/include'), PosixPath('/usr/local/cuda-10.1/lib64')}\n",
      "  warn(msg)\n",
      "/home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/cuda-10.1/include:/usr/local/cuda-10.1/lib64::/usr/local/cuda/extras/CUPTI/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('shared_volume/e6dfced2-00b9-4b0e-9c33-bb5fd6af589a')}\n",
      "  warn(msg)\n",
      "/home/maziar/miniconda3/envs/pytorch2/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244400cdaccf4576955abf035eb58bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "model = LlamaForCausalLM.from_pretrained('LLaMA_HF/', load_in_8bit=True, torch_dtype=torch.float16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae7685b3-4c9b-487a-a0a9-2ae5c6b4bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_int8_training\n",
    "\n",
    "model = prepare_model_for_int8_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce1d1671-1a35-4fa9-8625-5b713860d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dc17c3d-3646-4c0d-b1a2-f8690f1c1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16d10a7d-2594-4aa1-8c7d-2f43778a9b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e001a46-6e9a-42fb-aaf9-70f7d4d23cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = torch.Tensor([tokenized_full_prompt[\"input_ids\"]]).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21c2c94c-8097-4571-8b18-01b809dd9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.forward(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e76b67e-28a6-4a5d-8430-a39443b200c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 86, 32000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d465a4a9-bac9-4664-ba12-58095374f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  450,   338,   263,   429,   284,   674,   920,  1158,   393,   607,\n",
       "         2859,   411,   263,  1967,   322,   338,   278,  2472, 29889,    13,\n",
       "          263,  1824,   393, 16612,  2486,  6089,  2167,   278,  3414, 29889,\n",
       "           13,  1576, 29905, 29937, 10567,   582,    13,    13,    13,  1598,\n",
       "          278,  1494,  2400,  2400,   278,   278,  1734,   393, 15270,  1259,\n",
       "        10541, 10541, 29889,    13,    13,  2277, 29937, 10567, 29901,    13,\n",
       "         1576, 10541,   471,  2955,   964,   278,  9815, 19922, 29889,    13,\n",
       "           13,  2277, 29937, 10604, 29901,    13,  1576,  7751,  9712,  2955,\n",
       "          964,   278, 18215, 29889,    13,     1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model_output['logits'], -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78ca05b0-6b85-4e31-8abf-f02228bb7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The is a exal will how method that whichired with a image and is the information.\n",
      " a program that describesately answerstes the task.\n",
      "The\\# Inputru\n",
      "\n",
      "\n",
      "ify the following below below the the word that replacingting sentence sentence.\n",
      "\n",
      "### Input:\n",
      "The sentence wasured into the unknown waters.\n",
      "\n",
      "### Output:\n",
      "The ship ventured into the dangerous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(torch.argmax(model_output['logits'], -1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1908e3-7a8b-4b66-9db6-ca3df9178f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
